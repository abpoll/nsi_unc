from util.files import *
from util.const import *
from util.download import *
from util.unzip import *

configfile: "config/config.yaml"

# Run the download script
# Outputs all files in raw/
# that are specified by the
# key/value pairs 
# under config[county/state/national]["download"]
# Should be able to create
# functions in util/download.py
# that generate the list of
# output files for us
# TODO In the future, it could make sense
# to use command line tools like curl
rule download_data:
    output:
        dwnld_out_files(DOWNLOAD)
    conda:
        "workflow/envs/download.yaml"
    script:
        "workflow/scripts/download_data.py"

# Run the unzip util for all
# .zip files that were just downloaded
# Use the directory() to interim
# as the output
# TODO need to use wildcards
# in the directory structure
# to make this more generalizable
rule unzip:
    input:
        # Helper function to figure out
        # where our .zip files are
        zipped_downloads()
    output:
        # Helper function to indicate
        # where we expand our .zip directories
        # We need to control this programmatically
        # because the directory structure is
        # a little complex (but this structure
        # is helpful for defining in/out files
        # in later rules)
        [directory(x) for x in unzipped_downloads()]
    script:
        # easiest to call a script
        "workflow/scripts/unzip_data.py"

# Ok, now the logic is coming together
# For rule process, 
# we are processing all the data we just 
# expanded. Since we know the specific
# files we need to load, I can 
# specify -- with wildcards -- exactly
# the input files for this
# and exactly the output files for this
# The logic becomes simpler
# I think we pass in FIPS, STATEABBR, etc.
# through params? 


# Then there's a generate ensemble rule
# Again, we know exactly the files
# that go in and out of this

# Then there's the merge_hazard rule

# Then there's the assess_ensemble rule