# In the future, it makes sense to generate the county & state
# config from a pre-config script that takes in user input
# for which counties or areas they want to study. Then, 
# the config.yaml is generated from this user input
# in the following structure so that snakemake can do its
# magic. We would want to distribute jobs by 
# nation, state, county so they could run in parallel

# For the current version of UNSAFE, the config
# parameters of FIPS, STATEFIPS,
# STATEABBR, and NATION are not used. These are
# provided as an example. 
FIPS: ["42101"]
STATEFIPS: ["42"]
STATEABBR: ["PA"]
NATION: ["US"]

# Below are urls and api endpoints
# for obtaining all raw data
# We will organize by county, state
# and national downloads
# And then, within each, we will
# organize by url and api calls
# Finally, we will include key/val pairs
# for component type (i.e. haz, exp, vuln)
# and other identifiers (i.e. social, physical)
# that are useful for organizational logic

# There are different rules for downloading
# data from API or URL endpoints, since the former
# require some parameters whereas the latter
# point straight to a file to download
# We will first have keys
# for api/url 
# Then we will structure by keys
# for the data type (i.e. haz/exp)
# that will define file directories and paths
# These all need to be nested within 
# the following keys
# county, state, national, external
# we want to download data from
# largest to smallest scale (i.e. national, state, county)
# because of their set-type relationships (i.e. many counties in one state
# and many states in one nation)
download:
  FIPS:
    api:
      exp: 
        # NSI has an API endpoint
        # We call it county by county
        nsi: "https://nsi.sec.usace.army.mil/nsiapi/structures?fips={FIPS}"
  STATEABBR:
    url:
      vuln:
        social:
          # replace STATE_ABBR with state abbreviation in the download rule
          # We have a helper function in a util/ directory that replaces
          # STATE with the STATE key at the top of this config.yml file
          # This is the NOAA SOVI data
          noaa: "https://coast.noaa.gov/htdata/SocioEconomic/SoVI2010/SoVI_2010_{STATEABBR}.zip"
      ref:
        # replace STATE_FIPS with st_fips in the download rule
        # We have a helper function in a util/ directory that replaces
        # Tract, block group, and block geospatial boundaries are available at state level
        tract: "https://www2.census.gov/geo/tiger/TIGER2022/TRACT/tl_2022_{STATEFIPS}_tract.zip"
        bg: "https://www2.census.gov/geo/tiger/TIGER2022/BG/tl_2022_{STATEFIPS}_bg.zip"
        block: "https://www2.census.gov/geo/tiger/TIGER2022/TABBLOCK20/tl_2022_{STATEFIPS}_tabblock20.zip"
  NATION:
    url:
      vuln:
        social:
          # CEJST and low moderate income designations available for the whole country
          # I'm having trouble downloading lmi from the url endpoint
          # so just downloaded that separately from
          # https://www.hudexchange.info/sites/onecpd/assets/File/ACS_2015_lowmod_blockgroup_all.xlsx
          # and uploaded it the raw/ directory
          cejst: "https://static-data-screeningtool.geoplatform.gov/data-versions/1.0/data/score/downloadable/1.0-communities.csv"
      ref:
        # County and zip code tabulation area spatial data available for the whole country
        county: "https://www2.census.gov/geo/tiger/TIGER2022/COUNTY/tl_2022_us_county.zip"
        zcta: "https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip"
# We need to keep track of the format different api data is returned in
# to write it out
api_ext:
  nsi: ".json"

# We need to keep track of which wildcards are used in urls
url_wildcards: ["{FIPS}", "{STATEABBR}", "{STATEFIPS}", "{NATION}"]

# Keep track of NSI CRS
nsi_crs: "EPSG:4326"

# Dictionary of reference filenames to 
# what we want them to say
ref_names:
  tract: "tract"
  tabblock20: "block"
  bg: "bg"
  county: "county"
  zcta520: "zcta"

# Dictionary of ref names to their
# id column
ref_id_names:
  tract: "GEOID"
  block: "GEOID20"
  bg: "GEOID"
  zcta: "GEOID20"

# Constants for loss estimation
# Uncertainty for structure values
# State of the art automated valuation models
# are generally mean unbiased
# This paper https://www.tandfonline.com/doi/full/10.1080/09599916.2020.1807587
# suggests that a linear model can capture ~ 40% of structure value
# estimates by w/in 10% of their value, and ~ 83% of structure value estimates
# by w/in 30% of their value
# We don't have guidance on what
# the accuracy of NJ assessments are
# We also don't have guidance on how well the
# NSI structure values are calibrated. They are modeled from
# a non-transparent process and do not come with uncertainty
# or bias estimates
# If we use guidance from the Krause et al. paper linked
# above, we can define a normal distribution that is centered
# at the predicted value and has a standard deviation
# equal to predicted value * .3. If you 
# look at the probability of getting a value > 
# the predicted value + predicted value *.3, it's
# around .158, and same for the other side. So
# we can push our scaling factor down a bit
# to try and get the probability 
# of being above or under 
# predicted value + predicted value *.3
# to around .1 on either side. That would be
# consistent with the finding in Krause
# This leads to a scaling factor of about .25
# Another interpretation for this scaling factor
# is the coefficient of variation around
# the mean
coef_var: .25

# Dictionary of foundation types 
# Triangular distributions for first-floor elevation conditioned
# on foundation type
# From this repo: https://github.com/HenryGeorgist/go-fathom/
# blob/master/compute/foundationheights.go
# from the wing et al. 2022 paper
# distributions (min, most likely, max) conditioned on foundation type
# Tri(0, .5, 1.5|Slab)
# Tri(0, 1.5, 4|Crawl)
# Tri(0, 1.5, 4|Basement)
# Tri(6, 9, 12|Pier)
# Tri (6, 9, 12|Pile)
# For this case study, only need 'S', 'C', and 'B'
ffe_dict:
  S: [0, .5, 1.5]
  C: [0, 1.5, 4]
  B: [0, 1.5, 4]

# Number of SOWs
sows: 10000